{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b7ea094",
   "metadata": {},
   "source": [
    "# PA3 - DynaQ - Abe Leite {-}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df06cc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code can be used to add a folder in the repository to the Python import\n",
    "# path, irrespective of whether the notebook is being run in colab or Jupyter.\n",
    "# (C) 2020 Abe Leite, Indiana University Bloomington\n",
    "# This code block is released under MIT license. Feel free to make use of\n",
    "# this code in any projects so long as you reproduce this text.\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "repo_URL = 'https://github.com/ajleite/dyna-q-exploration'\n",
    "repo_name = repo_URL.split('/')[-1]\n",
    "# top level of repository. --AL Mar 10 2022\n",
    "code_folder = ''\n",
    "\n",
    "try:\n",
    "  repo_path = subprocess.check_output('git rev-parse --show-toplevel', shell=True).decode().strip()\n",
    "except subprocess.CalledProcessError:\n",
    "  os.system(f'git clone {repo_URL} --depth 1')\n",
    "  repo_path = os.path.abspath(repo_name)\n",
    "\n",
    "code_path = os.path.join(repo_path, code_folder)\n",
    "sys.path.append(code_path)\n",
    "print(f'Loading code from {code_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c838a505",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# don't forget the boilerplate --AL Mar 10 2022\n",
    "!apt-get update\n",
    "!apt-get install python-opengl -y\n",
    "!apt install xvfb -y\n",
    "!pip install pyvirtualdisplay\n",
    "!pip install piglet\n",
    "!pip install gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110420dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we'll go to the repo path in order to work with saved models. --AL Mar 10 2022\n",
    "os.chdir(code_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf43efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import gym"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe12200",
   "metadata": {},
   "source": [
    "# 0 Tasks {-}\n",
    "\n",
    "For this assignment I make use of one task: the Atari Pong task. I did the same preprocessing here that I did on the first programming assignment, and I will discuss it again now. Additionally, I fed the image output through a CNN that had been trained for a previous controller during PA1.\n",
    "\n",
    "## 0.1 Pong task {-}\n",
    "\n",
    "I preprocessed the game's video output as follows: (1) I disentangled the colors of the player, opponent, and ball; (2) I scaled the game field down by a factor of 2; (3) I restricted the image to the game field; and (4) I added a time-delayed image so that the agent could extract velocity information from the game. The resulting observations had dimensions of (80, 80, 6). Additionally, (4) I restricted the agent's actions to upwards and downwards motion (not including any no-op action); and finally (5) I treated each point, rather than each full game, as a distinct episode.\n",
    "\n",
    "I used a CNN to extract features from the Pong task. In particular, I the feature extractors from a CNN that had been trained end-to-end with a Monte-Carlo reinforcement learning algorithm.\n",
    "\n",
    "Please see all of this preprocessing code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcacc843",
   "metadata": {},
   "outputs": [],
   "source": [
    "def downscale(image):\n",
    "    new_image = np.zeros((image.shape[0]//2, image.shape[1]//2, image.shape[2]), image.dtype)\n",
    "    for new_row in range(new_image.shape[0]):\n",
    "        old_row = new_row * 2\n",
    "        for new_col in range(new_image.shape[1]):\n",
    "            old_col = new_col * 2\n",
    "            new_image[new_row, new_col] = image[old_row, old_col]\n",
    "    return new_image\n",
    "\n",
    "def preprocess(image):\n",
    "    bg = image[0, -1]\n",
    "\n",
    "    # restrict to the playing field\n",
    "    field = image[17:97]\n",
    "\n",
    "    ball_color = np.uint8([[[236, 236, 236]]])\n",
    "    P1_color = np.uint8([[[92, 186, 92]]])\n",
    "    P2_color = np.uint8([[[213, 130, 74]]])\n",
    "\n",
    "    # disentangle features insofar as possible\n",
    "    is_ball = np.all(field == ball_color, axis=-1)\n",
    "    is_P1 = np.all(field == P1_color, axis=-1)\n",
    "    is_P2 = np.all(field == P2_color, axis=-1)\n",
    "    new_image = np.float32(np.stack([is_ball, is_P1, is_P2], axis=2))\n",
    "\n",
    "    return new_image\n",
    "\n",
    "class PongTaskWithCNN:\n",
    "    def __init__(self, rng):\n",
    "        self.pong_env = gym.make('PongNoFrameskip-v0')\n",
    "        self.obs_buffer = [None, None, None]\n",
    "        self.obs_index = -3\n",
    "        self.points = 0\n",
    "\n",
    "        self.rng = rng\n",
    "        self.CNN = load_CNN()\n",
    "\n",
    "        self.real_reset()\n",
    "\n",
    "        def real_reset(self):\n",
    "        self.obs_index = -3\n",
    "        self.points = 0\n",
    "\n",
    "        self.pong_env.seed(int(self.rng.integers(2**31)))\n",
    "        raw_obs = self.pong_env.reset()\n",
    "        obs = preprocess(downscale(raw_obs))\n",
    "        self.obs_buffer[self.obs_index] = obs\n",
    "        self.obs_index += 1\n",
    "\n",
    "        # this returns the output of the CNN at the linear_decisions_2 layer, rather than the action quality layer.\n",
    "        return self.CNN.apply_headless(np.concatenate([obs, obs], axis=2))\n",
    "\n",
    "    def reset(self):\n",
    "        if self.obs_index >= 0:\n",
    "            self.obs_buffer[0] = self.obs_buffer[self.obs_index-1]\n",
    "            self.obs_index = -3\n",
    "        return self.CNN.apply_headless(np.concatenate([self.obs_buffer[0], self.obs_buffer[0]], axis=2))\n",
    "\n",
    "    def step(self, action):\n",
    "        if action == 0:\n",
    "            action = 2\n",
    "        else:\n",
    "            action = 5\n",
    "        raw_obs, reward, terminal, info = self.pong_env.step(action)\n",
    "\n",
    "        if terminal:\n",
    "            if not reward:\n",
    "                if self.points < 0:\n",
    "                    reward = -1.\n",
    "                else:\n",
    "                    reward = 1.\n",
    "    \n",
    "            combined_obs = self.real_reset()\n",
    "        else:\n",
    "            obs = preprocess(downscale(raw_obs))\n",
    "\n",
    "            if self.obs_index < 0:\n",
    "                old_obs = self.obs_buffer[0]\n",
    "            else:\n",
    "                old_obs = self.obs_buffer[self.obs_index]\n",
    "\n",
    "            self.obs_buffer[self.obs_index] = obs\n",
    "            self.obs_index += 1\n",
    "            if self.obs_index >= 3:\n",
    "                self.obs_index = 0\n",
    "\n",
    "            combined_obs = self.CNN.apply_headless(np.concatenate([obs, old_obs], axis=2))\n",
    "\n",
    "            if reward:\n",
    "                terminal = 1\n",
    "                self.points += reward\n",
    "\n",
    "        return combined_obs, reward, terminal, info\n",
    "\n",
    "    def render(self):\n",
    "        self.pong_env.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3edefd84",
   "metadata": {},
   "source": [
    "## 0.3 Simulation model {-}\n",
    "\n",
    "The following cell contains boilerplate code for training an agent on an environment and saving the results. It greedily evaluates the policy every 50 training episodes in order to track how performance changes over time and preserve the best-performing weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad4cfcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Simulation:\n",
    "    def __init__(self, agent, task, num_episodes, epsilon=0.25, path=None):\n",
    "        self.agent = agent\n",
    "        self.task = task\n",
    "\n",
    "        self.num_episodes = num_episodes\n",
    "        self.epsilon = epsilon\n",
    "        self.path = path\n",
    "\n",
    "        self.training_episode_rewards = []\n",
    "        self.eval_episode_rewards = []\n",
    "        self.eval_indices = []\n",
    "\n",
    "        self.episode_behavior_entropy = []\n",
    "        self.episode_dyn_rmse = []\n",
    "        self.episode_Q_rmse = []\n",
    "\n",
    "        self.best_weights = None\n",
    "        self.best_100_episode_return = None\n",
    "\n",
    "    def save_trace(self):\n",
    "        if not self.path:\n",
    "            return\n",
    "\n",
    "        to_save = {'best_weights': self.best_weights, 'best_100_episode_return': self.best_100_episode_return,\n",
    "            'training_episode_rewards': self.training_episode_rewards, 'eval_episode_rewards': self.eval_episode_rewards,\n",
    "            'eval_indices': self.eval_indices,\n",
    "            'dyn_rmse': self.episode_dyn_rmse, 'Q_rmse': self.episode_Q_rmse, 'behavior_entropy': self.episode_behavior_entropy}\n",
    "\n",
    "        pickle.dump(to_save, open(self.path,'wb'))\n",
    "\n",
    "    def evaluate(self, eval_index=None, render=False):\n",
    "        eval_rewards = []\n",
    "        for i in range(50):\n",
    "            s = self.task.reset()\n",
    "            t = False\n",
    "            ep_return = 0\n",
    "\n",
    "            while not t:\n",
    "                a = self.agent.act(s, 0)\n",
    "\n",
    "                s2, r, t, _ = self.task.step(a)\n",
    "                s = s2\n",
    "                ep_return += r\n",
    "\n",
    "                if render:\n",
    "                    self.task.render()\n",
    "\n",
    "            # episode is over, record it\n",
    "            eval_rewards.append(ep_return)\n",
    "            print((eval_index, 'e', i, ep_return))\n",
    "\n",
    "        self.eval_indices.append(eval_index)\n",
    "        self.eval_episode_rewards.append(eval_rewards)\n",
    "\n",
    "        # maintain best stats\n",
    "        if self.best_100_episode_return is None or np.mean(eval_rewards) > self.best_100_episode_return:\n",
    "            self.best_100_episode_return = np.mean(eval_rewards)\n",
    "            self.best_weights = self.agent.Q_network.keras_network.get_weights()\n",
    "        print('cycle', eval_index, 'mean eval:', np.mean(eval_rewards), 'best:', self.best_100_episode_return)\n",
    "        self.save_trace()\n",
    "\n",
    "    def run(self, render=False):\n",
    "        timestep = 0\n",
    "\n",
    "        for n in range(self.num_episodes):\n",
    "            # gather greedy evaluation trajectories every 50 training episodes\n",
    "            if not n % 50 and n:\n",
    "                self.evaluate(n, render)\n",
    "\n",
    "            # 1. gather training trajectories\n",
    "            s = self.task.reset()\n",
    "            t = False\n",
    "            total_r = 0\n",
    "\n",
    "            n_left = 0\n",
    "            n_right = 0\n",
    "\n",
    "            ep_Q_rmse = 0\n",
    "            ep_Q_loss_den = 0\n",
    "            ep_dyn_rmse = 0\n",
    "            ep_dyn_loss_den = 0\n",
    "\n",
    "            while not t:\n",
    "                a = self.agent.act(s, self.epsilon)\n",
    "\n",
    "                if a == 0:\n",
    "                    n_left += 1\n",
    "                else:\n",
    "                    n_right += 1\n",
    "\n",
    "                s2, r, t, _ = self.task.step(a)\n",
    "                mean_Q_loss, mean_dyn_loss = self.agent.store(s, a, r, t, s2)\n",
    "                s = s2\n",
    "                total_r += r\n",
    "\n",
    "                if not mean_Q_loss is None:\n",
    "                    ep_Q_rmse += mean_Q_loss\n",
    "                    ep_Q_loss_den += 1\n",
    "                if not mean_dyn_loss is None:\n",
    "                    ep_dyn_rmse += mean_dyn_loss\n",
    "                    ep_dyn_loss_den += 1\n",
    "\n",
    "            # episode is over, record it\n",
    "            self.training_episode_rewards.append(total_r)\n",
    "            print((n, 't', total_r))\n",
    "\n",
    "            # calculate behavior entropy\n",
    "            total_actions = n_left + n_right\n",
    "            p_left = n_left / total_actions\n",
    "            p_right = n_right / total_actions\n",
    "            if p_left == 0 or p_right == 0:\n",
    "                entropy = 0.\n",
    "            else:\n",
    "                entropy = -np.log2(p_left)*p_left + -np.log2(p_right)*p_right\n",
    "            self.episode_behavior_entropy.append(entropy)\n",
    "\n",
    "            if ep_Q_loss_den:\n",
    "                self.episode_Q_rmse.append(ep_Q_rmse/ep_Q_loss_den)\n",
    "                print(ep_Q_rmse/ep_Q_loss_den)\n",
    "            if ep_dyn_loss_den:\n",
    "                self.episode_dyn_rmse.append(ep_dyn_rmse/ep_dyn_loss_den)\n",
    "                print(ep_dyn_rmse/ep_dyn_loss_den)\n",
    "\n",
    "        # everything is done!\n",
    "        self.evaluate(self.num_episodes, render)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e3bd8d",
   "metadata": {},
   "source": [
    "# 1 Network design {-}\n",
    "\n",
    "## 1.1 CNN preprocesses visual input {-}\n",
    "\n",
    "To extract features from visual inputs, I used a pretrained CNN (which had been originally been a part of the policy network on a Monte-Carlo agent on this task). This CNN takes in an 80x80x6 visual input, including channels for self, other, and ball at both the present time and t - 4. This input image is fed into two sets of convolutions. The first is a set of 12 5x5 filters, which are immediately max pooled over the entire image. This is intended to allow the agent to recognize exceptional patterns (such as a ball about to pass the player in some direction) that would otherwise be missed. The second is a set of 12 3x3 filters, which are then max pooled with a pool size and stride of 8x8 pixels. This is intended to capture local dynamics cues and their rough relative positions. The resulting 10x10x12 and 1x1x12 images are flattened and concatenated into a 1212 unit vector, and then fed through hidden layers of 50 and 20 units. The output of this 20-unit hidden layer is then used as a representation for client networks.\n",
    "\n",
    "Please see the code to describe and load this network below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4108ab5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_CNN():\n",
    "    obs_shape = (80, 80, 6)\n",
    "    action_count = 2\n",
    "\n",
    "    def network_factory(input):\n",
    "        exceptional_cues = tf.keras.layers.GlobalMaxPool2D()(tf.keras.layers.Conv2D(12, 5, padding='same', activation='relu')(input)) # params: 6x5x5x12+12, size: 12\n",
    "        local_dynamics_cues = tf.keras.layers.Conv2D(12, 3, padding='same', activation='relu')(input) # params: 6x3x3x12+12, size: 80x80x12\n",
    "        coarse_dynamics = tf.keras.layers.MaxPool2D(pool_size=(8, 8), padding='same')(local_dynamics_cues) # size: 10x10x12\n",
    "        locationwise_coarse_dynamics = tf.keras.layers.Flatten()(coarse_dynamics) # size: 1200\n",
    "        all_cues = tf.keras.layers.Concatenate(axis=-1)([locationwise_coarse_dynamics, exceptional_cues]) # size: 1212\n",
    "\n",
    "        linear_decisions_1 = tf.keras.layers.Dense(50, activation='relu')(all_cues) # params: 1212x50+50, size: 50\n",
    "        linear_decisions_2 = tf.keras.layers.Dense(20, activation='relu')(linear_decisions_1) # params: 50x20+20, size: 20\n",
    "\n",
    "        return linear_decisions_2\n",
    "\n",
    "    n = network.CNN(obs_shape, action_count, network_factory, 0.0004)\n",
    "\n",
    "    p = pickle.load(open(f'out/MC-Pong-1.pickle','rb'))\n",
    "    n.keras_network.set_weights(p['best_weights'])\n",
    "\n",
    "    return n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076bc595",
   "metadata": {},
   "source": [
    "## 1.2 Q-network determines policy {-}\n",
    "\n",
    "I use a simple Q network design to determine the agent's actions. This network takes in a preprocessed observation (by the CNN described above) through 20 input units; it then feeds this input through ReLU hidden layers of 50 and 20 units before projecting it onto a 2-dimensional linear output layer encoding Q values of the two possible actions.\n",
    "\n",
    "Please see the code to create this network below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf4dcf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pong_PostCNN_config(task_rng):\n",
    "    obs_shape = (20,)\n",
    "    action_count = 2\n",
    "\n",
    "    Q_network = network.FFANN(obs_shape, action_count, [50, 20], 0.0001)\n",
    "\n",
    "    task = tasks.PongTaskWithCNN(task_rng)\n",
    "\n",
    "    return 'Pong-PostCNN', obs_shape, action_count, Q_network, task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd6e9cd",
   "metadata": {},
   "source": [
    "## 1.3 Dynamics network predicts reward, termination, and subsequent state {-}\n",
    "\n",
    "For the function approximation implementation of DynaQ, a feed-forward network accepts a flat input that concatenates the observation and candidate action (one-hot encoded) vectors, then feeds it through two 100-unit fully-connected ReLU layers. Finally, these hidden representations are fed into a linear output layer that includes the predicted reward, predicted termination (which is subsequently passed through the sigmoid function), and predicted subsequent state.\n",
    "\n",
    "I used large 100-unit hidden layers and a high training rate of 0.05 to avoid forgetting problems. This network is trained on single instances, and doing this reliably requires both a high learning rate and a network with a large enough latent capacity to encode relationships that are not active during every training step.\n",
    "\n",
    "Please see the code to create this network below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24196d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DynaNN:\n",
    "    def __init__(self, obs_shape, action_count, hidden_layer_sizes, learning_rate):\n",
    "        self.obs_shape = obs_shape\n",
    "        self.action_count = action_count\n",
    "        self.hidden_layer_sizes = hidden_layer_sizes\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        input_shape = (np.prod(obs_shape) + action_count,)\n",
    "        SA_input = tf.keras.layers.Input(shape=input_shape)\n",
    "\n",
    "        next_input = SA_input\n",
    "        for hidden_layer, hidden_layer_size in enumerate(hidden_layer_sizes):\n",
    "            next_input = tf.keras.layers.Dense(hidden_layer_size, activation='relu', kernel_initializer='random_normal', bias_initializer='random_normal')(next_input)\n",
    "\n",
    "        # want the immediate reward, the termination likelihood, and the predicted next obs\n",
    "        output_shape = 2 + np.prod(obs_shape)\n",
    "        linear_output = tf.keras.layers.Dense(output_shape)(next_input)\n",
    "\n",
    "        self.keras_network = tf.keras.Model(SA_input, linear_output)\n",
    "\n",
    "        self.optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
    "\n",
    "    @tf.function\n",
    "    def apply(self, S, A):\n",
    "        if A.dtype == tf.int32 or A.dtype == tf.int64:\n",
    "            A = tf.one_hot(A, self.action_count)\n",
    "\n",
    "        expanded = False\n",
    "\n",
    "        if len(A.shape) == 1:\n",
    "            expanded = True\n",
    "            S = tf.expand_dims(S, axis=0)\n",
    "            A = tf.expand_dims(A, axis=0)\n",
    "\n",
    "        S_A = tf.concat([tf.reshape(S, (S.shape[0], -1)), A], axis=1)\n",
    "\n",
    "        out = self.keras_network(S_A)\n",
    "\n",
    "        R_pred = out[:, 0]\n",
    "        T_pred = tf.nn.sigmoid(out[:, 1])\n",
    "        S2_pred = tf.reshape(out[:, 2:], S.shape)\n",
    "\n",
    "        if expanded:\n",
    "            return tf.squeeze(R_pred, axis=0), tf.squeeze(T_pred, axis=0), tf.squeeze(S2_pred, axis=0)\n",
    "        else:\n",
    "            return R_pred, T_pred, S2_pred\n",
    "\n",
    "    @tf.function\n",
    "    def fit(self, S, A, R, T, S2):\n",
    "        R_pred, T_pred, S2_pred = self.apply(S, A)\n",
    "\n",
    "        R_loss = tf.reduce_sum((R - R_pred) ** 2) * 100\n",
    "        T_loss = -tf.reduce_sum(T * tf.math.log(T_pred) + (1 - T) * tf.math.log(1 - T_pred)) * 100\n",
    "\n",
    "        S2_loss = tf.reduce_sum((S2_pred - S2) ** 2)\n",
    "\n",
    "        total_loss = R_loss + T_loss + S2_loss\n",
    "\n",
    "        gradient = tf.gradients(total_loss, self.keras_network.weights)\n",
    "        self.optimizer.apply_gradients(zip(gradient, self.keras_network.weights))\n",
    "\n",
    "        return total_loss\n",
    "\n",
    "# later on: experience_buffer = experience_store.HybridBuffer(obs_shape, action_count, [100, 100], 0.05, experience_buffer_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b78b080",
   "metadata": {},
   "source": [
    "## 1.4 Network design (implementation details) {-}\n",
    "\n",
    "Here you may find the code used to implement the underlying CNN and FFANN classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929aaf19",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FFANN:\n",
    "    def __init__(self, obs_shape, action_count, hidden_layer_sizes, learning_rate):\n",
    "        self.obs_shape = obs_shape\n",
    "        self.action_count = action_count\n",
    "        self.hidden_layer_sizes = hidden_layer_sizes\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        obs_input = tf.keras.layers.Input(shape=obs_shape)\n",
    "\n",
    "        next_input = obs_input\n",
    "        for hidden_layer, hidden_layer_size in enumerate(hidden_layer_sizes):\n",
    "            next_input = tf.keras.layers.Dense(hidden_layer_size, activation='relu', kernel_initializer='random_normal', bias_initializer='random_normal')(next_input)\n",
    "\n",
    "        linear_output = tf.keras.layers.Dense(action_count)(next_input)\n",
    "\n",
    "        self.keras_network = tf.keras.Model(obs_input, linear_output)\n",
    "\n",
    "        self.optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
    "\n",
    "    @tf.function\n",
    "    def apply(self, S, A):\n",
    "        return tf.gather(self.keras_network(S), A, batch_dims=1)\n",
    "\n",
    "    @tf.function\n",
    "    def apply_V(self, S):\n",
    "        return tf.reduce_max(self.keras_network(S), axis=1)\n",
    "\n",
    "    @tf.function\n",
    "    def apply_A(self, S):\n",
    "        a = tf.argmax(self.keras_network(S), axis=1)\n",
    "        return a\n",
    "\n",
    "    @tf.function\n",
    "    def fit(self, S, A, Q):\n",
    "        Q_predicted = self.apply(S, A)\n",
    "        # tf.print(S[0], A[0], Q[0], Q_predicted[0])\n",
    "        Q_loss = tf.reduce_sum((Q_predicted - Q) ** 2)\n",
    "\n",
    "        Q_gradient = tf.gradients(Q_loss, self.keras_network.weights)\n",
    "        self.optimizer.apply_gradients(zip(Q_gradient, self.keras_network.weights))\n",
    "\n",
    "        return Q_loss\n",
    "\n",
    "    def copy_from(self, other, amount):\n",
    "        for self_w, other_w in zip(self.keras_network.weights, other.keras_network.weights):\n",
    "            self_w.assign(self_w*(1-amount) + other_w*amount)\n",
    "\n",
    "    def copy(self):\n",
    "        other = FFANN(self.obs_shape, self.action_count, self.hidden_layer_sizes, self.learning_rate)\n",
    "        other.copy_from(self, 1)\n",
    "        return other\n",
    "\n",
    "    def zero_like(self):\n",
    "        other = FFANN(self.obs_shape, self.action_count, self.hidden_layer_sizes, self.learning_rate)\n",
    "        for other_w in other.keras_network.weights:\n",
    "            other_w.assign(tf.zeros_like(other_w))\n",
    "        return other\n",
    "\n",
    "class CNN:\n",
    "    def __init__(self, obs_shape, action_count, network_factory, learning_rate):\n",
    "        self.obs_shape = obs_shape\n",
    "        self.action_count = action_count\n",
    "        self.network_factory = network_factory\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        obs_input = tf.keras.layers.Input(shape=obs_shape)\n",
    "\n",
    "        last_layer = network_factory(obs_input)\n",
    "\n",
    "        linear_output = tf.keras.layers.Dense(action_count)(last_layer)\n",
    "\n",
    "        self.keras_network = tf.keras.Model(obs_input, linear_output)\n",
    "        self.keras_network_headless = tf.keras.Model(obs_input, last_layer)\n",
    "\n",
    "        self.optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
    "\n",
    "    @tf.function\n",
    "    def apply(self, S, A):\n",
    "        return tf.gather(self.keras_network(S), A, batch_dims=1)\n",
    "\n",
    "    @tf.function\n",
    "    def apply_headless(self, S):\n",
    "        if len(S.shape) == 3:\n",
    "            single = True\n",
    "            S = tf.expand_dims(S, axis=0)\n",
    "        else:\n",
    "            single = False\n",
    "\n",
    "        out = self.keras_network_headless(S)\n",
    "\n",
    "        if single:\n",
    "            out = tf.squeeze(out, axis=0)\n",
    "\n",
    "        return out\n",
    "\n",
    "    @tf.function\n",
    "    def apply_V(self, S):\n",
    "        return tf.reduce_max(self.keras_network(S), axis=1)\n",
    "\n",
    "    @tf.function\n",
    "    def apply_A(self, S):\n",
    "        a = tf.argmax(self.keras_network(S), axis=1)\n",
    "        return a\n",
    "\n",
    "    @tf.function\n",
    "    def fit(self, S, A, Q):\n",
    "        Q_predicted = self.apply(S, A)\n",
    "        # tf.print(S[0], A[0], Q[0], Q_predicted[0])\n",
    "        Q_loss = tf.reduce_sum((Q_predicted - Q) ** 2)\n",
    "\n",
    "        Q_gradient = tf.gradients(Q_loss, self.keras_network.weights)\n",
    "        self.optimizer.apply_gradients(zip(Q_gradient, self.keras_network.weights))\n",
    "\n",
    "        return Q_loss\n",
    "\n",
    "    def copy_from(self, other, amount):\n",
    "        for self_w, other_w in zip(self.keras_network.weights, other.keras_network.weights):\n",
    "            self_w.assign(self_w*(1-amount) + other_w*amount)\n",
    "\n",
    "    def copy(self):\n",
    "        other = CNN(self.obs_shape, self.action_count, self.network_factory, self.learning_rate)\n",
    "        other.copy_from(self, 1)\n",
    "        return other\n",
    "\n",
    "    def zero_like(self):\n",
    "        other = CNN(self.obs_shape, self.action_count, self.network_factory, self.learning_rate)\n",
    "        for other_w in other.keras_network.weights:\n",
    "            other_w.assign(tf.zeros_like(other_w))\n",
    "        return other"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b654972e",
   "metadata": {},
   "source": [
    "# 2 Training algorithms {-}\n",
    "\n",
    "## 2.1 Common features {-}\n",
    "\n",
    "Both the version of DynaQ using an experience buffer and the version using dynamics function approximation share many features. In fact, since DynaQ does not do anything as sophisticated as generate full trajectories according to the dynamics model, nor does it sample from the distribution of *plausible* (S, A) pairs, rather than encountered ones, this comparison is largely an assessment of the ability of the dynamics function to encode an experience buffer.\n",
    "\n",
    "Each algorithm develops a Q function, which is used to determine policy. This Q function represents the long-term expected reward, up to some decay factor (I used 0.99), following some Observation/Action pair. The Q function is developed using TD(0) bootstrapping, as seen in the below `get_TD0_target_values` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a3bf02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_TD0_target_values(S, A, R, T, S2, target_V_function, discount_factor):\n",
    "    ''' Used to get a target value for the TD0 algorithm. '''\n",
    "\n",
    "    sample_count = S.shape[0]\n",
    "\n",
    "    ## generate the Q2 values\n",
    "    Q2 = np.array(target_V_function(S2))\n",
    "\n",
    "    # set the future reward to 0 when the transition is terminal\n",
    "    Q2 = np.where(T, 0, Q2)\n",
    "\n",
    "    ## apply the Bellman equation to derive the target Q1 values\n",
    "    return R + discount_factor * Q2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bbb16b3",
   "metadata": {},
   "source": [
    "The Q function is developed using a fixed number of experience buffer samples per training step. (This is the `N` term in the original Dyna-Q algorithm statement, and it is represented as `training_samples_per_experience_step` in my code.) This number is divided into minibatches and then the Q function at the appropriate action index is fit using the mean-squared error loss.\n",
    "Each algorithm used an epsilon-greedy policy, taking a random action 25% of the time.\n",
    "The shared code for the two algorithms is included below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152656fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TD0Agent:\n",
    "    def __init__(self, rng, action_count, Q_network, experience_buffer, training_samples_per_experience_step, minibatch_size, experience_period_length, target_Q_network_update_rate):\n",
    "        self.rng = rng\n",
    "\n",
    "        self.action_count = action_count\n",
    "        self.possible_actions = np.arange(self.action_count)\n",
    "\n",
    "        self.Q_network = Q_network\n",
    "        self.target_Q_network = self.Q_network.zero_like()\n",
    "        self.target_Q_network_update_rate = target_Q_network_update_rate\n",
    "\n",
    "        self.experience_buffer = experience_buffer\n",
    "\n",
    "        self.training_samples_per_experience_step = training_samples_per_experience_step\n",
    "        self.minibatch_size = minibatch_size\n",
    "        self.experience_period_length = experience_period_length\n",
    "\n",
    "        self.experience_period_step = 0\n",
    "\n",
    "        self.use_tqdm = False\n",
    "\n",
    "    def act(self, obs, epsilon=0.1):\n",
    "        if epsilon and self.rng.random() < epsilon:\n",
    "            return self.rng.integers(self.action_count)\n",
    "\n",
    "        return np.array(self.Q_network.apply_A(np.expand_dims(obs, axis=0))[0])\n",
    "\n",
    "    def sample_target_values(self, minibatch_size):\n",
    "        S, A, R, T, S2 = self.experience_buffer.sample_SARTS2(minibatch_size, self.rng)\n",
    "        if S.size > 0:\n",
    "            Q = get_TD0_target_values(S, A, R, T, S2, self.target_Q_network.apply_V, self.discount_factor)\n",
    "        else:\n",
    "            Q = np.zeros((), dtype=np.float32)\n",
    "\n",
    "        return S, A, Q\n",
    "\n",
    "    def store(self, obs, action, reward, terminal, obs_2):\n",
    "        dyn_loss = self.experience_buffer.store(obs, action, reward, terminal, obs_2)\n",
    "        self.experience_period_step += 1\n",
    "\n",
    "        # directly encode the most recent SARTS' tuple\n",
    "        Q = get_TD0_target_values(np.expand_dims(obs, axis=0), None, np.expand_dims(reward, axis=0), np.expand_dims(terminal, axis=0), np.expand_dims(obs_2, axis=0),self.target_Q_network.apply_V, self.discount_factor)\n",
    "        self.Q_network.fit(S, A, Q)\n",
    "\n",
    "        # train on previous samples\n",
    "        total_training_samples = self.training_samples_per_experience_step * self.experience_period_length\n",
    "        num_minibatches =  total_training_samples // self.minibatch_size\n",
    "        last_minibatch_size = total_training_samples % self.minibatch_size\n",
    "\n",
    "        total_loss = 0\n",
    "\n",
    "        if self.use_tqdm:\n",
    "            import tqdm\n",
    "            minibatches = tqdm.tqdm(range(num_minibatches))\n",
    "        else:\n",
    "            minibatches = range(num_minibatches)\n",
    "\n",
    "        for _ in minibatches:\n",
    "            S, A, Q = self.sample_target_values(self.minibatch_size)\n",
    "            if S.size > 0:\n",
    "                total_loss += self.Q_network.fit(S, A, Q)\n",
    "                # print(num_minibatches, _, total_loss)\n",
    "\n",
    "        if last_minibatch_size:\n",
    "            S, A, Q = self.sample_target_values(last_minibatch_size)\n",
    "            if S.size > 0:\n",
    "                total_loss += self.Q_network.fit(S, A, Q)\n",
    "\n",
    "        # if S.size > 0:\n",
    "        #     print(S[0], A[0], Q[0])\n",
    "        mean_loss = np.sqrt(np.array(total_loss)) / total_training_samples\n",
    "\n",
    "        if self.target_Q_network_update_rate:\n",
    "            total_target_update = 1 - (1-self.target_Q_network_update_rate)**total_training_samples\n",
    "            self.target_Q_network.copy_from(self.Q_network, amount=total_target_update)\n",
    "\n",
    "        # print(self.Q_network.keras_network(np.linspace(-1, 1, 11).reshape(-1, 1)))\n",
    "\n",
    "        self.experience_period_step = 0\n",
    "\n",
    "        return mean_loss, dyn_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73fe2e94",
   "metadata": {},
   "source": [
    "The difference between the two agents is in the type of experience store each uses. This difference will be covered in more detail below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67334590",
   "metadata": {},
   "source": [
    "## 2.2 Experience store without function approximation (direct RL learning) {-}\n",
    "\n",
    "The experience store for direct RL learning reliably stores up all experiences up to a fixed limit, at which point the oldest experiences are discarded. It stores full `SARTS'` tuples. Thus, sampling from this experience store is a way to reliably sample S, A, and the encountered reward, terminal value, and next state out of all encountered state/action pairs. The code implementing this buffer is included below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc525c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TD0Buffer:\n",
    "    def __init__(self, obs_shape, action_count, buffer_size):\n",
    "        self.S_samples = np.zeros((buffer_size,)+obs_shape, dtype=np.float32)\n",
    "        self.A_samples = np.zeros((buffer_size,), dtype=np.int32)\n",
    "        self.R_samples = np.zeros((buffer_size,), dtype=np.float32)\n",
    "        self.T_samples = np.zeros((buffer_size,), dtype=bool)\n",
    "\n",
    "        self.action_count = action_count\n",
    "\n",
    "        # buffer_size represents the size of the buffer.\n",
    "        # cur_index represents the next index that will be written.\n",
    "        # filled represents whether the buffer has been filled at least once (can be sampled freely).\n",
    "        self.buffer_size = buffer_size\n",
    "        self.cur_index = 0\n",
    "        self.filled = False\n",
    "\n",
    "    def store(self, obs, action, reward, terminal, obs_2):\n",
    "        ''' store should be called every timestep.\n",
    "\n",
    "\n",
    "            - obs should be a float32 array whose axes match obs_shape.\n",
    "            - action should be an int or int32.\n",
    "            - reward should be a float32.\n",
    "            - terminal should be a boolean.\n",
    "\n",
    "            Unless terminal was True for the last call to store,\n",
    "            this sample must correspond to the timestep immediately\n",
    "            following the sample passed to the last call. '''\n",
    "\n",
    "        self.S_samples[self.cur_index] = obs\n",
    "        self.A_samples[self.cur_index] = action\n",
    "        self.R_samples[self.cur_index] = reward\n",
    "        self.T_samples[self.cur_index] = terminal\n",
    "\n",
    "        self.cur_index += 1\n",
    "\n",
    "        if self.cur_index == self.buffer_size:\n",
    "            self.filled = True\n",
    "            self.cur_index = 0\n",
    "\n",
    "    def sample_SARTS2(self, batch_size, rng):\n",
    "        ''' Samples `batch_size` samples using the numpy random generator `rng`.\n",
    "\n",
    "            Returns them as a tuple (observations, actions, rewards, terminals, next observations),\n",
    "            where actions is now one-hot encoded.\n",
    "\n",
    "            Refuses to return the most recently stored tuple (since there is nothing to follow it) unless it was terminal.\n",
    "            Remember not to interpret next observation if terminal flag was set. '''\n",
    "\n",
    "        if not self.T_samples[self.cur_index-1]:\n",
    "            avoid_last_stored_sample = True\n",
    "        else:\n",
    "            avoid_last_stored_sample = False\n",
    "\n",
    "        # the strategy for avoiding the last stored sample is as follows:\n",
    "        # just don't generate it, if we have not looped.\n",
    "        # if have, then add 1 to all indices at or above it to avoid it.\n",
    "\n",
    "        if self.filled and avoid_last_stored_sample:\n",
    "            limit_index = self.buffer_size - 1\n",
    "        elif self.filled:\n",
    "            limit_index = self.buffer_size\n",
    "        elif avoid_last_stored_sample:\n",
    "            limit_index = self.cur_index - 1\n",
    "        else:\n",
    "            limit_index = self.cur_index\n",
    "\n",
    "        if limit_index > 0:\n",
    "            sample_indices = rng.integers(limit_index, size=(batch_size))\n",
    "        else:\n",
    "            sample_indices = np.zeros((0,), dtype=np.int32)\n",
    "\n",
    "        if self.filled and avoid_last_stored_sample and self.cur_index != 0:\n",
    "            sample_indices = np.where(sample_indices >= self.cur_index - 1, sample_indices + 1, sample_indices)\n",
    "\n",
    "        # construct the indices for S2 by adding 1 to the existing sample indices, being sure to wrap around.\n",
    "        next_indices = np.where(sample_indices == self.buffer_size - 1, 0, sample_indices + 1)\n",
    "\n",
    "        return self.S_samples[sample_indices], self.A_samples[sample_indices], \\\n",
    "            self.R_samples[sample_indices], self.T_samples[sample_indices], self.S_samples[next_indices]\n",
    "\n",
    "    def clear(self):\n",
    "        self.cur_index = 0\n",
    "        self.filled = False\n",
    "\n",
    "class DQNAgent(TD0Agent):\n",
    "    def __init__(self, rng, obs_shape, action_count, Q_network, discount_factor, experience_buffer_size, training_samples_per_experience_step, minibatch_size, experience_period_length, target_Q_network_update_rate):\n",
    "        experience_buffer = TD0Buffer(obs_shape, action_count, experience_buffer_size)\n",
    "        self.discount_factor = discount_factor\n",
    "        BaseAgent.__init__(self, rng, action_count, Q_network, experience_buffer, training_samples_per_experience_step, minibatch_size, experience_period_length, target_Q_network_update_rate)\n",
    "\n",
    "def test_DQN_Agent(seed, config, *args, replay=False, render=False, episodes=2500, **kwargs):\n",
    "    agent_rng = np.random.default_rng(seed)\n",
    "    task_rng = np.random.default_rng(seed+234579672983459873)\n",
    "\n",
    "    task_name, obs_shape, action_count, Q_network, task = config(task_rng, *args, **kwargs)\n",
    "\n",
    "    discount_factor = 0.99\n",
    "    experience_buffer_size = 100000\n",
    "    training_samples_per_experience_step = 2048\n",
    "    minibatch_size = 512\n",
    "    experience_period_length = 1\n",
    "    target_Q_network_update_rate = 0.00001\n",
    "\n",
    "    if replay:\n",
    "        experience_period_length = -1\n",
    "        target_Q_network_update_rate = 0\n",
    "\n",
    "    ag = agent.TD0Agent(agent_rng, obs_shape, action_count, Q_network, discount_factor, experience_buffer_size, training_samples_per_experience_step, minibatch_size, experience_period_length, target_Q_network_update_rate)\n",
    "\n",
    "    path = f'out/DQN-{task_name}-{seed}.pickle'\n",
    "\n",
    "    sim = simulation.Simulation(ag, task, episodes, 0.25, path=path)\n",
    "\n",
    "    if replay:\n",
    "        p = pickle.load(open(path,'rb'))\n",
    "        ag.Q_network.keras_network.set_weights(p['best_weights'])\n",
    "        sim.path = None\n",
    "        sim.evaluate(render=True)\n",
    "    else:\n",
    "        sim.run(render)\n",
    "\n",
    "    return sim\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0058cf4",
   "metadata": {},
   "source": [
    "## 2.2 Experience store using function approximation (Dyna-Q learning) {-}\n",
    "\n",
    "The experience store for Dyna-Q learning takes a hybrid approach. It reliably stores all encountered state/action pairs up to a fixed limit, at which point the oldest experiences are discarded. However, it does not store reward, terminal state, or subsequent state information directly. Instead, it encodes these through a dynamics model. This means that sampling from this experience store will reliably provide encountered states, but may not provide perfect information about the subsequent state.\n",
    "\n",
    "A further refinement would be to use a probabilistic model such as a VAE to represent the space of possibly encountered state/action pairs. I did not take this approach. But the existence of this approach is why I call my experience store \"hybrid\" rather than a \"function approximation\" store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c7c55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HybridBuffer:\n",
    "    ''' This buffer stores all of the S, A pairs verbatim, but uses a dynamics network to obtain R, T, and S2. '''\n",
    "    def __init__(self, obs_shape, action_count, hidden_layer_sizes, learning_rate, buffer_size):\n",
    "        self.S_samples = np.zeros((buffer_size,)+obs_shape, dtype=np.float32)\n",
    "        self.A_samples = np.zeros((buffer_size,), dtype=np.int32)\n",
    "\n",
    "        self.action_count = action_count\n",
    "\n",
    "        self.dynann = network.DynaNN(obs_shape, action_count, hidden_layer_sizes, learning_rate)\n",
    "\n",
    "        # buffer_size represents the size of the buffer.\n",
    "        # cur_index represents the next index that will be written.\n",
    "        # filled represents whether the buffer has been filled at least once (can be sampled freely).\n",
    "        self.buffer_size = buffer_size\n",
    "        self.cur_index = 0\n",
    "        self.filled = False\n",
    "\n",
    "    def store(self, obs, action, reward, terminal, obs_2):\n",
    "        ''' store should be called every timestep.\n",
    "\n",
    "\n",
    "            - obs should be a float32 array whose axes match obs_shape.\n",
    "            - action should be an int or int32.\n",
    "            - reward should be a float32.\n",
    "            - terminal should be a boolean.\n",
    "\n",
    "            Unless terminal was True for the last call to store,\n",
    "            this sample must correspond to the timestep immediately\n",
    "            following the sample passed to the last call. '''\n",
    "\n",
    "        self.S_samples[self.cur_index] = obs\n",
    "        self.A_samples[self.cur_index] = action\n",
    "\n",
    "        self.cur_index += 1\n",
    "\n",
    "        if self.cur_index == self.buffer_size:\n",
    "            self.filled = True\n",
    "            self.cur_index = 0\n",
    "\n",
    "        pre = self.dynann.apply(obs, action)\n",
    "        loss = self.dynann.fit(obs, action, reward, terminal, obs_2)\n",
    "        post = self.dynann.apply(obs, action)\n",
    "\n",
    "        # print(reward, terminal, obs_2.numpy())\n",
    "        # print(*(i.numpy() for i in pre))\n",
    "        # print(*(i.numpy() for i in post))\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def sample_SARTS2(self, batch_size, rng):\n",
    "        ''' Samples `batch_size` samples using the numpy random generator `rng`.\n",
    "\n",
    "            Returns them as a tuple (observations, actions, rewards, terminals, next observations),\n",
    "            where actions is now one-hot encoded.\n",
    "\n",
    "            Refuses to return the most recently stored tuple (since there is nothing to follow it) unless it was terminal.\n",
    "            Remember not to interpret next observation if terminal flag was set. '''\n",
    "\n",
    "        avoid_last_stored_sample = True\n",
    "\n",
    "        # the strategy for avoiding the last stored sample is as follows:\n",
    "        # just don't generate it, if we have not looped.\n",
    "        # if have, then add 1 to all indices at or above it to avoid it.\n",
    "\n",
    "        if self.filled and avoid_last_stored_sample:\n",
    "            limit_index = self.buffer_size - 1\n",
    "        elif self.filled:\n",
    "            limit_index = self.buffer_size\n",
    "        elif avoid_last_stored_sample:\n",
    "            limit_index = self.cur_index - 1\n",
    "        else:\n",
    "            limit_index = self.cur_index\n",
    "\n",
    "        if limit_index > 0:\n",
    "            sample_indices = rng.integers(limit_index, size=(batch_size))\n",
    "        else:\n",
    "            sample_indices = np.zeros((0,), dtype=np.int32)\n",
    "\n",
    "        if self.filled and avoid_last_stored_sample and self.cur_index != 0:\n",
    "            sample_indices = np.where(sample_indices >= self.cur_index - 1, sample_indices + 1, sample_indices)\n",
    "\n",
    "        # construct the indices for S2 by adding 1 to the existing sample indices, being sure to wrap around.\n",
    "        next_indices = np.where(sample_indices == self.buffer_size - 1, 0, sample_indices + 1)\n",
    "\n",
    "        S, A = self.S_samples[sample_indices], self.A_samples[sample_indices]\n",
    "        R, T, S2 = self.dynann.apply(S, A)\n",
    "        T = T > 0.5\n",
    "\n",
    "        return S, A, R, T, S2\n",
    "\n",
    "    def clear(self):\n",
    "        self.cur_index = 0\n",
    "        self.filled = False\n",
    "\n",
    "class DynaQAgent(TD0Agent):\n",
    "    def __init__(self, rng, obs_shape, action_count, Q_network, discount_factor, experience_buffer_size, training_samples_per_experience_step, minibatch_size, experience_period_length, target_Q_network_update_rate):\n",
    "        experience_buffer = experience_store.HybridBuffer(obs_shape, action_count, [100, 100], 0.05, experience_buffer_size)\n",
    "        self.discount_factor = discount_factor\n",
    "        BaseAgent.__init__(self, rng, action_count, Q_network, experience_buffer, training_samples_per_experience_step, minibatch_size, experience_period_length, target_Q_network_update_rate)\n",
    "\n",
    "def test_DynaQ_Agent(seed, config, *args, replay=False, render=False, episodes=2500, **kwargs):\n",
    "    agent_rng = np.random.default_rng(seed)\n",
    "    task_rng = np.random.default_rng(seed+234579672983459873)\n",
    "\n",
    "    task_name, obs_shape, action_count, Q_network, task = config(task_rng, *args, **kwargs)\n",
    "\n",
    "    discount_factor = 0.99\n",
    "    experience_buffer_size = 100000\n",
    "    training_samples_per_experience_step = 2048\n",
    "    minibatch_size = 512\n",
    "    experience_period_length = 1\n",
    "    target_Q_network_update_rate = 0.00001\n",
    "\n",
    "    if replay:\n",
    "        experience_period_length = -1\n",
    "        target_Q_network_update_rate = 0\n",
    "\n",
    "    ag = agent.DynaQAgent(agent_rng, obs_shape, action_count, Q_network, discount_factor, experience_buffer_size, training_samples_per_experience_step, minibatch_size, experience_period_length, target_Q_network_update_rate)\n",
    "\n",
    "    path = f'out/DynaQ-{task_name}-{seed}.pickle'\n",
    "\n",
    "    sim = simulation.Simulation(ag, task, episodes, 0.25, path=path)\n",
    "\n",
    "    if replay:\n",
    "        p = pickle.load(open(path,'rb'))\n",
    "        ag.Q_network.keras_network.set_weights(p['best_weights'])\n",
    "        sim.path = None\n",
    "        sim.evaluate(render=True)\n",
    "    else:\n",
    "        sim.run(render)\n",
    "\n",
    "    return sim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae239b9",
   "metadata": {},
   "source": [
    "## 2.4 Main simulations {-}\n",
    "\n",
    "Uncomment the line disabling the following cell and run it to reproduce the simulations for the main assignment. The results are all already saved in the repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7cb0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "enable_simulations_main = False\n",
    "\n",
    "# enable_simulations_main = True\n",
    "\n",
    "if enable_simulations_main:\n",
    "    for i in range(5):\n",
    "        test_DQN_Agent(i)\n",
    "        test_DynaQ_Agent(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef31618",
   "metadata": {},
   "source": [
    "# 3 Experiment results {-}\n",
    "\n",
    "## 3.0 Plotting code {-}\n",
    "\n",
    "The following code was used to report and plot my experiment results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2a5f0445",
   "metadata": {},
   "outputs": [],
   "source": [
    "def last_n_average(values, n):\n",
    "    values = np.array(values)\n",
    "    n = min(n, values.size)\n",
    "    num = np.cumsum(values)\n",
    "    den = np.cumsum(np.ones_like(values))\n",
    "    prev_num = np.concatenate([np.zeros(n), num[:-n]], axis=0)\n",
    "    prev_den = np.concatenate([np.zeros(n), den[:-n]], axis=0)\n",
    "    return (num-prev_num)/(den-prev_den)\n",
    "\n",
    "def load_records(condition, seeds):\n",
    "    records = []\n",
    "    for s in seeds:\n",
    "        records.append(pickle.load(open(f'out/{condition}-{s}.pickle', 'rb')))\n",
    "    return records\n",
    "\n",
    "def plot_training_curves(records, suptitle='Training progress', out_fn=None):\n",
    "    training_returns = [record['training_episode_rewards'] for record in records]\n",
    "    evaluation_returns = [[np.mean(r) for r in record['eval_episode_rewards']] for record in records]\n",
    "    Q_loss = [record['Q_rmse'] for record in records]\n",
    "    dyn_loss = [record['dyn_rmse'] for record in records]\n",
    "    training_cycle_length = 50\n",
    "    training_cycle_count = len(records[0]['training_episode_rewards'])/50\n",
    "    training_episode_count = len(records[0]['training_episode_rewards'])\n",
    "\n",
    "    training_episode_numbers = np.arange(0, training_episode_count)\n",
    "\n",
    "    eval_cycle_length = 50\n",
    "\n",
    "    eval_episode_numbers = records[0]['eval_indices']\n",
    "\n",
    "    plt.figure()\n",
    "    for i, title, x_axis, runs in zip([1,2,3,4], ['Train return (running mean)', 'Eval return', 'Q loss (RMSE)', 'Dynamics loss'], [training_episode_numbers, eval_episode_numbers, training_episode_numbers, training_episode_numbers], [training_returns, evaluation_returns, Q_loss, dyn_loss]):\n",
    "        if not runs[0]:\n",
    "            continue\n",
    "\n",
    "        if runs is training_returns:\n",
    "            runs = [last_n_average(run, 100) for run in runs]\n",
    "            # title = title+' (running mean)'\n",
    "\n",
    "        run_length = np.min([len(run) for run in runs])\n",
    "        runs = [run[:run_length] for run in runs]\n",
    "        x_axis = x_axis[:run_length]\n",
    "\n",
    "        plt.subplot(2,2,i)\n",
    "        plt.title(title)\n",
    "\n",
    "        if len(runs) > 1:\n",
    "            mean_run = np.mean(runs, axis=0)\n",
    "\n",
    "            run_l, run_h = st.t.interval(0.95, len(runs)-1, loc=mean_run, scale=st.sem(runs, axis=0))\n",
    "\n",
    "            plt.fill_between(x_axis, run_l, run_h, color='black', alpha=0.25)\n",
    "            plt.plot(x_axis, run_l, color='black', lw=0.5, ls='--')\n",
    "            plt.plot(x_axis, run_h, color='black', lw=0.5, ls='--', label='95% c.i.')\n",
    "\n",
    "        label = (i == 2)\n",
    "        for run in runs:\n",
    "            if len(runs) == 1:\n",
    "                plt.plot(x_axis, run, label='indiv. run')\n",
    "            elif label:\n",
    "                plt.plot(x_axis, run, alpha=0.25, label='indiv. run')\n",
    "            else:\n",
    "                plt.plot(x_axis, run, alpha=0.25)\n",
    "            label = False\n",
    "\n",
    "        if len(runs) > 1:\n",
    "            plt.plot(x_axis, mean_run, color='red', label='mean run')\n",
    "\n",
    "        if i == 2:\n",
    "            plt.legend(bbox_to_anchor=(1.05, 1.0), loc='upper left')\n",
    "\n",
    "        if i > 2:\n",
    "            plt.xlabel('Episode')\n",
    "\n",
    "    plt.suptitle(suptitle)\n",
    "    plt.subplots_adjust(left=0.1, bottom=0.1, right=0.78, hspace=0.3, wspace=0.25)\n",
    "\n",
    "    if not out_fn is None:\n",
    "        plt.savefig(out_fn)\n",
    "        plt.close()\n",
    "\n",
    "def plot_performance(DQN_records, DynaQ_records, task_name, out_fn=None):\n",
    "    DQN_perfs = [record['best_100_episode_return'] for record in DQN_records]\n",
    "    DynaQ_perfs = [record['best_100_episode_return'] for record in DynaQ_records]\n",
    "\n",
    "    print(f\"DQN on {task_name}: {np.mean(DQN_perfs)} +/- {np.std(DQN_perfs)}\")\n",
    "    print(f\"DynaQ on {task_name}: {np.mean(DynaQ_perfs)} +/- {np.std(DynaQ_perfs)}\")\n",
    "\n",
    "    plt.figure()\n",
    "    plt.title(f'Per-run best performance on {task_name} task')\n",
    "    plt.violinplot([DQN_perfs, DynaQ_perfs], showmeans=True)\n",
    "    plt.gca().xaxis.set_ticks([1,2],['DQN','DynaQ'])\n",
    "    plt.ylabel('100-episode mean return')\n",
    "\n",
    "    if not out_fn is None:\n",
    "        plt.savefig(out_fn)\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4abfe9f",
   "metadata": {},
   "source": [
    "## 3.1 Results on the Pong task with pretrained visual inputs {-}\n",
    "\n",
    "As seen in the below figure, a DynaQ implementation with a perfect experience store (\"DQN\") significantly outperformed an implementation with a hybrid experience store using function approximation (\"DynaQ\"). I will further discuss the training curves and the quality of the discovered policies in the following subsections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1b3a8425",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DQN on Pong: -0.56 +/- 0.0\n",
      "DynaQ on Pong: -0.92 +/- 0.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_performance(load_records(\"DQN-Pong-PostCNN\", range(1,2)), load_records(\"DynaQ-Pong-PostCNN\", range(1,2)), 'Pong')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529f56be",
   "metadata": {},
   "source": [
    "### 3.1.1 DQN results on the Pong task {-}\n",
    "\n",
    "#### 3.1.1.1 Training DQN on the Pong task {-}\n",
    "\n",
    "A figure is shown below depicting smoothed on-policy training returns, greedy policy evaluation performed every 50 training episodes, and the Q loss (root mean squared error) over 1 run of 2000 training episodes applying DynaQ with perfect experience store on the Pong task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9e5a9655",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_training_curves(load_records(\"DQN-Pong-PostCNN\", range(1,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2b3544",
   "metadata": {},
   "source": [
    "Training on the task showed mixed results, with occasional transient jumps in performance (which were also captured in the evaluation data) and a possible upwards trend at the end of the run. The level of instability suggests that a larger neural network or lower training rate might be useful. The fact that the Q loss was relatively steady throughout training suggests that there was not a strong enough signal differentiating good from bad policies; this could perhaps be remediated by increasing the discount factor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec96bce",
   "metadata": {},
   "source": [
    "#### 3.1.1.2 Evaluating DQN on the Pong task {-}\n",
    "\n",
    "As seen in the figure at the heading of Section 3.1, the best policy discovered by DQN on the Pong task received a mean reward of -0.56 over 100 episodes. This represents winning 22% of the points on average. This is certainly above chance level, but nevertheless very unimpressive performance on the task. It is worth noting that the Monte Carlo agent from which this CNN was extracted achieved a mean return of -0.02 using this CNN, so it is unlikely to be the fault of the feature extractor that DQN failed to achieve high performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3161c9",
   "metadata": {},
   "source": [
    "### 3.1.2 DynaQ results on the Pong task {-}\n",
    "\n",
    "#### 3.1.2.1 Training DynaQ on the Pong task {-}\n",
    "\n",
    "A figure is shown below depicting smoothed on-policy training returns, greedy policy evaluation performed every 50 training episodes, the Q-function loss (root mean squared error), and the dynamics function representation loss (RMSE for reward and state plus cross-entropy for the termination flag), over 1 runs of 400 training episodes applying DynaQ to the Pong task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d2baf54a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_training_curves(load_records(\"DynaQ-Pong-PostCNN\", range(1,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b53ec2",
   "metadata": {},
   "source": [
    "At this level, I am not comfortable saying that DynaQ discovers a policy better than chance. It is worth noting that the dynamics model and the Q function loss seem highly nonconvergent. Given the fact that loss spikes do not occur every episode, but that the player does not win as many episodes as there are loss spikes, I suspect that the issue is that the player cannot predict being able to hit the ball, and that the loss spikes occur because there are so many more state transitions where the player does not hit the ball than where it does."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e319760",
   "metadata": {},
   "source": [
    "#### 3.1.2.2 Evaluating DynaQ on the Pong task {-}\n",
    "\n",
    "As seen in the figure at the heading of Section 3.1, the best policy discovered by this run of DynaQ achieved a 100-episode mean return of -0.92. This represents winning 4% of points on average, which I suspect is near or at chance level."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46bff3e9",
   "metadata": {},
   "source": [
    "# 4 Discussion {-}\n",
    "\n",
    "## 4.1 DQN vs DynaQ on the Pong task {-}\n",
    "\n",
    "In this experiment I found that DynaQ with hybrid function approximation underperformed DynaQ with a perfect experience store (\"DQN\"). I have also found reason to believe that this is because DynaQ's dynamics model did not converge (as seen in the dynamics loss figure). While it is very possible that, had I had more time to tune hyperparameters, I could have found more compelling results, the challenge of training a dynamics model would remain.\n",
    "\n",
    "In fact, we cannot possibly expect DynaQ to outperform DQN in this framework because the best that DynaQ can do is to perfectly approximate the information that the DQN's perfect experience store preserves by nature. Instead, this is a useful measure of the value that is lost by switching from a perfect experience store to one that uses a dynamics model. However, as discussed in class, there are significant advantages to be had using dynamics models in more sophisticated ways. If, instead of sampling (S, A) pairs from the agent's history, the dynamics model generated entirely new trajectories (as some of Michael's work with Dr. Piergiovanni does) then it could enable better interpolation between experienced trajectories and lead to more stable and sample-efficient learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60e307c",
   "metadata": {},
   "source": [
    "# 5 Code availability {-}\n",
    "\n",
    "You may find all of the code for this assignment, including supporting data, at https://github.com/ajleite/dyna-q-exploration. You may particularly find and test out this notebook at https://github.com/ajleite/continuous-rl-exploration/blob/main/PA3_DynaQ_Abe_Leite.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
